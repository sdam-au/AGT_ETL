{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EbixMMZchOgn"
   },
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9878,
     "status": "ok",
     "timestamp": 1588779837403,
     "user": {
      "displayName": "Vojtěch Kaše",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggz3jS9e7I3GdIEbyBKFtqr9tPdNCwyLBEJwbK8cw=s64",
      "userId": "01399835024022498543"
     },
     "user_tz": -120
    },
    "id": "QWRXmeoNhLsD",
    "outputId": "ae5620d8-2479-4587-c6ed-cdf64706b2a3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import logging ### to monitor the code\n",
    "from bs4 import BeautifulSoup\n",
    "import xml.etree.cElementTree as ET\n",
    "import pickle\n",
    "import math\n",
    "import random\n",
    "import sys\n",
    "import csv\n",
    "import unicodedata\n",
    "import requests\n",
    "from urllib.request import urlopen \n",
    "import io\n",
    "import getpass\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from itertools import islice # to iterate through dicts\n",
    "\n",
    "import nltk\n",
    "from nltk.collocations import *\n",
    "\n",
    "#!pip3 install pyconll #\n",
    "import pyconll # universal dependencies parser\n",
    "\n",
    "### plotting\n",
    "### to use latex (important for greek fonts)\n",
    "#! apt-get install texlive-latex-recommended \n",
    "#! apt install texlive-latex-extra\n",
    "#! apt install dvipng\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import gspread\n",
    "from gspread_dataframe import get_as_dataframe, set_with_dataframe\n",
    "from google.oauth2 import service_account # based on google-auth library\n",
    "\n",
    "import sddk\n",
    "\n",
    "#from anda import gr\n",
    "# OR uncomment the following:\n",
    "script_url = \"https://raw.githubusercontent.com/sdam-au/anda_py/master/anda/gr.py\"\n",
    "exec(requests.get(script_url).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11242,
     "status": "ok",
     "timestamp": 1588774498489,
     "user": {
      "displayName": "Vojtěch Kaše",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggz3jS9e7I3GdIEbyBKFtqr9tPdNCwyLBEJwbK8cw=s64",
      "userId": "01399835024022498543"
     },
     "user_tz": -120
    },
    "id": "cmC88KhGh7n2",
    "outputId": "4356c03e-47e1-4a6b-dc69-cf21efc97e0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sciencedata.dk username (format '123456@au.dk'): 648597@au.dk\n",
      "sciencedata.dk password: ········\n",
      "connection with shared folder established with you as its owner\n",
      "endpoint variable has been configured to: https://sciencedata.dk/files/SDAM_root/\n"
     ]
    }
   ],
   "source": [
    "conf = sddk.configure(\"SDAM_root\", \"648597@au.dk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_wKUMZ-yjvEn"
   },
   "outputs": [],
   "source": [
    "# to access gsheet, you need Google Service Account key json file\n",
    "# I have mine located in my personal space on sciencedata.dk, so I read it from there:\n",
    "\n",
    "# (1) read the file and parse its content\n",
    "file_data = conf[0].get(\"https://sciencedata.dk/files/ServiceAccountsKey.json\").json()\n",
    "# (2) transform the content into crendentials object\n",
    "credentials = service_account.Credentials.from_service_account_info(file_data)\n",
    "# (3) specify your usage of the credentials\n",
    "scoped_credentials = credentials.with_scopes(['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive'])\n",
    "# (4) use the constrained credentials for authentication of gspread package\n",
    "gc = gspread.Client(auth=scoped_credentials)\n",
    "\n",
    "AGT_overview = gc.open_by_url(\"https://docs.google.com/spreadsheets/d/1iVta_FuEDgUM_Lf_yByrdbbXNoVH_dnVZs6QRyYv1NM/edit?usp=sharing\")\n",
    "\n",
    "# AGT_metadata = gc.open_by_url(\"https://docs.google.com/spreadsheets/d/1hEUnL3E07F-EnE3wYnk1V91aXfPDrcnhFHKjD-04CM0/edit?usp=sharing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data\n",
    "AGT = sddk.read_file(\"SDAM_data/AGT/AGT_dated_20201027.json\", \"df\", conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219532769"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AGT_string = \" \".join(AGT[\"string\"].tolist())\n",
    "len(AGT_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ἀρχόμενος ³σέο, Φοῖβε, text in latin also CAPITAL ⁴παλαιγενέων 1234 κλέα 34056 φωτῶν μνήσομαι, οἳ Πόντοιο κατὰ στόμα καὶ διὰ πέτρας Κυανέας βασιλῆος ἐφημοσύνῃ Πελίαο χρύσειον μετὰ κῶας ἐύζυγον ἤλασαν Ἀργώ. τοίην γὰρ Πελίης φάτιν ἔκλυεν, ὥς μιν ὀπίσσω μοῖρα μένει στυγερή, τοῦδʼ ἀνέρος, ὅντινʼ ἴδοιτο δημόθεν οἰοπέδιλον, ὑπʼ ἐννεσίῃσι δαμῆναι.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_string = \"ἀρχόμενος ³σέο, Φοῖβε, text in latin also CAPITAL ⁴παλαιγενέων 1234 κλέα 34056 φωτῶν μνήσομαι, οἳ Πόντοιο κατὰ στόμα καὶ διὰ πέτρας Κυανέας βασιλῆος ἐφημοσύνῃ Πελίαο χρύσειον μετὰ κῶας ἐύζυγον ἤλασαν Ἀργώ. τοίην γὰρ Πελίης φάτιν ἔκλυεν, ὥς μιν ὀπίσσω μοῖρα μένει στυγερή, τοῦδʼ ἀνέρος, ὅντινʼ ἴδοιτο δημόθεν οἰοπέδιλον, ὑπʼ ἐννεσίῃσι δαμῆναι.\"\n",
    "test_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ἀρχόμενος ³σέο, Φοῖβε,      ⁴παλαιγενέων  κλέα  φωτῶν μνήσομαι, οἳ Πόντοιο κατὰ στόμα καὶ διὰ πέτρας Κυανέας βασιλῆος ἐφημοσύνῃ Πελίαο χρύσειον μετὰ κῶας ἐύζυγον ἤλασαν Ἀργώ. τοίην γὰρ Πελίης φάτιν ἔκλυεν, ὥς μιν ὀπίσσω μοῖρα μένει στυγερή, τοῦδʼ ἀνέρος, ὅντινʼ ἴδοιτο δημόθεν οἰοπέδιλον, ὑπʼ ἐννεσίῃσι δαμῆναι.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove numerical superscripts\n",
    "sups = [\"¹\", \"²\", \"³\", \"⁴\",\"⁵\", \"⁶\", \"⁷\", \"⁰\", \"⁹\"]\n",
    "def remove_sups(string):\n",
    "    for sup in sups:\n",
    "        string = string.replace(sup, \"\")\n",
    "    return string\n",
    "\n",
    "def grave_to_acute(string):\n",
    "    GRAVE = \"\\u0300\"\n",
    "    ACUTE = \"\\u0301\"\n",
    "    return unicodedata.normalize(\"NFC\", \"\".join(unicodedata.normalize(\"NFD\", string).replace(GRAVE, ACUTE)))\n",
    "\n",
    "test_string_1 = re.sub(\"[a-zA-Z0-9]\", \"\", test_string)\n",
    "test_string_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ἀρχόμενος', 'σέο,', 'Φοῖβε,', 'παλαιγενέων', 'κλέα', 'φωτῶν', 'μνήσομαι,', 'οἵ', 'Πόντοιο', 'κατά', 'στόμα', 'καί', 'διά', 'πέτρας', 'Κυανέας', 'βασιλῆος', 'ἐφημοσύνῃ', 'Πελίαο', 'χρύσειον', 'μετά', 'κῶας', 'ἐύζυγον', 'ἤλασαν', 'Ἀργώ.', 'τοίην', 'γάρ', 'Πελίης', 'φάτιν', 'ἔκλυεν,', 'ὥς', 'μιν', 'ὀπίσσω', 'μοῖρα', 'μένει', 'στυγερή,', 'τοῦδʼ', 'ἀνέρος,', 'ὅντινʼ', 'ἴδοιτο', 'δημόθεν', 'οἰοπέδιλον,', 'ὑπʼ', 'ἐννεσίῃσι', 'δαμῆναι.']\n"
     ]
    }
   ],
   "source": [
    "test_string_2 = remove_sups(test_string_1)\n",
    "test_string_3 = grave_to_acute(test_string_2)\n",
    "print(test_string_3.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column with sentences\n",
    "\n",
    "def get_sentences(string):\n",
    "  sentences = [s.strip() for s in re.split(\"\\·|\\.|\\:|\\;\", unicodedata.normalize(\"NFC\", string))]\n",
    "  return sentences\n",
    "\n",
    "AGT[\"sentences\"] = AGT[\"string\"].apply(get_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>string</th>\n",
       "      <th>wordcount</th>\n",
       "      <th>author_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>raw_date</th>\n",
       "      <th>date_avr</th>\n",
       "      <th>date_probs</th>\n",
       "      <th>date_manual</th>\n",
       "      <th>provenience</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tlg0001.tlg001.perseus-grc2.xml</td>\n",
       "      <td>Apollonius Rhodius</td>\n",
       "      <td>Argonautica</td>\n",
       "      <td>ἀρχόμενος σέο, Φοῖβε, παλαιγενέων κλέα φωτῶν μ...</td>\n",
       "      <td>38822</td>\n",
       "      <td>tlg0001</td>\n",
       "      <td>tlg0001.tlg001</td>\n",
       "      <td>3 B.C.</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>{'-2.5': 1}</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>pagan</td>\n",
       "      <td>[ἀρχόμενος σέο, Φοῖβε, παλαιγενέων κλέα φωτῶν ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tlg0003.tlg001.perseus-grc2.xml</td>\n",
       "      <td>Thucydides</td>\n",
       "      <td>The Peloponnesian War</td>\n",
       "      <td>\\nΘουκυδίδης Ἀθηναῖος ξυνέγραψε τὸν πόλεμον τῶ...</td>\n",
       "      <td>150126</td>\n",
       "      <td>tlg0003</td>\n",
       "      <td>tlg0003.tlg001</td>\n",
       "      <td>5 B.C.</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>{'-4.5': 1}</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>pagan</td>\n",
       "      <td>[Θουκυδίδης Ἀθηναῖος ξυνέγραψε τὸν πόλεμον τῶν...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tlg0004.tlg001.perseus-grc1.xml</td>\n",
       "      <td>Diogenes Laertius</td>\n",
       "      <td>Lives of Eminent Philosophers</td>\n",
       "      <td>Τὸ τῆς φιλοσοφίας ἔργον ἔνιοί φασιν ἀπὸ βαρβάρ...</td>\n",
       "      <td>110773</td>\n",
       "      <td>tlg0004</td>\n",
       "      <td>tlg0004.tlg001</td>\n",
       "      <td>A.D. 3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>{'2.5': 1}</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>[Τὸ τῆς φιλοσοφίας ἔργον ἔνιοί φασιν ἀπὸ βαρβά...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tlg0005.tlg001.perseus-grc1.xml</td>\n",
       "      <td>Theocritus</td>\n",
       "      <td>Idylls</td>\n",
       "      <td>\\n̔Αδύ τι τὸ ψιθύρισμα καὶ ἁ πίτυς αἰπόλε τήνα...</td>\n",
       "      <td>19200</td>\n",
       "      <td>tlg0005</td>\n",
       "      <td>tlg0005.tlg001</td>\n",
       "      <td>4-3 B.C.</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>{'-3.5': 0.5, '-2.5': 0.5}</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>[̔Αδύ τι τὸ ψιθύρισμα καὶ ἁ πίτυς αἰπόλε τήνα,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tlg0005.tlg002.perseus-grc1.xml</td>\n",
       "      <td>Theocritus</td>\n",
       "      <td>Epigrams</td>\n",
       "      <td>τὰ ῥόδα τὰ δροσόεντα καὶ ἁ κατάπυκνος ἐκείνα ἕ...</td>\n",
       "      <td>1734</td>\n",
       "      <td>tlg0005</td>\n",
       "      <td>tlg0005.tlg002</td>\n",
       "      <td>4-3 B.C.</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>{'-3.5': 0.5, '-2.5': 0.5}</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>[τὰ ῥόδα τὰ δροσόεντα καὶ ἁ κατάπυκνος ἐκείνα ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          filename              author  \\\n",
       "0  tlg0001.tlg001.perseus-grc2.xml  Apollonius Rhodius   \n",
       "1  tlg0003.tlg001.perseus-grc2.xml          Thucydides   \n",
       "2  tlg0004.tlg001.perseus-grc1.xml   Diogenes Laertius   \n",
       "3  tlg0005.tlg001.perseus-grc1.xml          Theocritus   \n",
       "4  tlg0005.tlg002.perseus-grc1.xml          Theocritus   \n",
       "\n",
       "                           title  \\\n",
       "0                    Argonautica   \n",
       "1          The Peloponnesian War   \n",
       "2  Lives of Eminent Philosophers   \n",
       "3                        Idylls    \n",
       "4                      Epigrams    \n",
       "\n",
       "                                              string  wordcount author_id  \\\n",
       "0  ἀρχόμενος σέο, Φοῖβε, παλαιγενέων κλέα φωτῶν μ...      38822   tlg0001   \n",
       "1  \\nΘουκυδίδης Ἀθηναῖος ξυνέγραψε τὸν πόλεμον τῶ...     150126   tlg0003   \n",
       "2  Τὸ τῆς φιλοσοφίας ἔργον ἔνιοί φασιν ἀπὸ βαρβάρ...     110773   tlg0004   \n",
       "3  \\n̔Αδύ τι τὸ ψιθύρισμα καὶ ἁ πίτυς αἰπόλε τήνα...      19200   tlg0005   \n",
       "4  τὰ ῥόδα τὰ δροσόεντα καὶ ἁ κατάπυκνος ἐκείνα ἕ...       1734   tlg0005   \n",
       "\n",
       "           doc_id  raw_date  date_avr                  date_probs  \\\n",
       "0  tlg0001.tlg001    3 B.C.      -2.5                 {'-2.5': 1}   \n",
       "1  tlg0003.tlg001    5 B.C.      -4.5                 {'-4.5': 1}   \n",
       "2  tlg0004.tlg001    A.D. 3       2.5                  {'2.5': 1}   \n",
       "3  tlg0005.tlg001  4-3 B.C.      -3.0  {'-3.5': 0.5, '-2.5': 0.5}   \n",
       "4  tlg0005.tlg002  4-3 B.C.      -3.0  {'-3.5': 0.5, '-2.5': 0.5}   \n",
       "\n",
       "   date_manual provenience                                          sentences  \n",
       "0         -2.5       pagan  [ἀρχόμενος σέο, Φοῖβε, παλαιγενέων κλέα φωτῶν ...  \n",
       "1         -4.5       pagan  [Θουκυδίδης Ἀθηναῖος ξυνέγραψε τὸν πόλεμον τῶν...  \n",
       "2          NaN              [Τὸ τῆς φιλοσοφίας ἔργον ἔνιοί φασιν ἀπὸ βαρβά...  \n",
       "3          NaN              [̔Αδύ τι τὸ ψιθύρισμα καὶ ἁ πίτυς αἰπόλε τήνα,...  \n",
       "4          NaN              [τὰ ῥόδα τὰ δροσόεντα καὶ ἁ κατάπυκνος ἐκείνα ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AGT.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w4W20C24h4i6"
   },
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fuSy8EjJhqfx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 26s, sys: 2.2 s, total: 2min 28s\n",
      "Wall time: 2min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "AGT[\"lemmata\"] = AGT.apply(lambda row: lemmatize_string(row[\"string\"], all_lemmata=False, filter_by_postag=[\"n\", \"a\", \"v\"], involve_unknown=True), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lemmata = []\n",
    "for work in AGT[\"lemmata\"].tolist():\n",
    "    all_lemmata.extend(work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 562,
     "status": "ok",
     "timestamp": 1588778017873,
     "user": {
      "displayName": "Vojtěch Kaše",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggz3jS9e7I3GdIEbyBKFtqr9tPdNCwyLBEJwbK8cw=s64",
      "userId": "01399835024022498543"
     },
     "user_tz": -120
    },
    "id": "Ma5jS1U4lU9M",
    "outputId": "e6982d6f-e208-440f-eb8e-2bf233fe17d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13812934"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AGT[\"lemmata_wordcount\"] = AGT.apply(lambda row: len(row[\"lemmata\"]), axis=1)\n",
    "AGT[\"lemmata_wordcount\"].sum() # previously we had 13925726, then 13713183"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m_gRYawLZYaF"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def lemmatize_sentences(sentences):\n",
    "    lemmatized_sentences = []\n",
    "    for sentence in sentences:\n",
    "        lemmatized_sentence = lemmatize_string(sentence, all_lemmata=False, filter_by_postag=[\"n\", \"a\", \"v\"], involve_unknown=True)\n",
    "        lemmatized_sentences.append(lemmatized_sentence)\n",
    "    return lemmatized_sentences\n",
    "\n",
    "AGT[\"lemmatized_sentences\"] = AGT[\"sentences\"].apply(lemmatize_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGT[\"n_sentences\"] = AGT['lemmatized_sentences'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at some string\n",
    "# e.g. paul's letter to the Galatians\n",
    "AGT[AGT[\"author_id\"]==\"tlg0031paul\"].iloc[3][\"string\"][:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and its lemmatized version\n",
    "print(AGT[AGT[\"author_id\"]==\"tlg0031paul\"].iloc[3][\"lemmata\"][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# straightforward corrections might be added here\n",
    "\n",
    "corrections = {\n",
    "    \"ἔχις\" : \"ἔχω\"\n",
    "}\n",
    "\n",
    "for key in corrections.keys():\n",
    "    AGT[\"lemmata\"] = AGT[\"lemmata\"].apply(lambda word_list: [corrections[key] if x == key else x for x in word_list])\n",
    "    AGT[\"lemmatized_sentences\"] = AGT[\"lemmatized_sentences\"].apply(lambda sentences_list: [[corrections[key] if x == key else x for x in sentence] for sentence in sentences_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sddk.write_file(\"SDAM_data/AGT/AGT_20201110.json\", AGT, conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM+taOvEihjuZ2k0d8Zjz/M",
   "collapsed_sections": [],
   "name": "2_METADATA&LEMMATIZATION&OVERVIEW.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
