{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pyconll\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plac\n",
    "import random\n",
    "from pathlib import Path\n",
    "from spacy.util import minibatch, compounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang=\"el\"\n",
    "# initatize en empty model\n",
    "nlp = spacy.blank(lang)\n",
    "# add the tagger to the pipeline\n",
    "# nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "tagger = nlp.create_pipe(\"tagger\")\n",
    "    # Add the tags. This needs to be done before you start training.\n",
    "#for tag, values in TAG_MAP.items():\n",
    "#    tagger.add_label(tag, values)\n",
    "nlp.add_pipe(tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/ag_lemma_lookup.json\"\n",
    "ag_lemma_lookup = json.load(open(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lookups import Lookups\n",
    "lookups = Lookups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/ag_lemma_lookup.json\"\n",
    "ag_lemma_lookup = json.load(open(path))\n",
    "table = lookups.add_table(\"ag_lemma_lookup\", ag_lemma_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lemmatizer import Lemmatizer\n",
    "lemmatizer = Lemmatizer(lookups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training our own model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract first part of training data\n",
    "corpus_perseus = pyconll.load.iter_from_url(\"https://raw.githubusercontent.com/UniversalDependencies/UD_Ancient_Greek-Perseus/master/grc_perseus-ud-train.conllu\")\n",
    "\n",
    "corpus_proiel = pyconll.load.iter_from_url(\"https://raw.githubusercontent.com/UniversalDependencies/UD_Ancient_Greek-PROIEL/master/grc_proiel-ud-train.conllu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_perseus = []\n",
    "for sentence in corpus_perseus:\n",
    "    words, tags = [], []\n",
    "    for token in sentence:\n",
    "        words.append(token.form)\n",
    "        tags.append(token.upos)\n",
    "    train_data_perseus.append((sentence.text, {\"words\" : words, \"tags\" : tags}))\n",
    "        #forms_lemmas_dict[token.form] = [{\"l\" : token.lemma, \"p\" : token.xpos, \"s\" : \"\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_proiel = []\n",
    "for sentence in corpus_proiel:\n",
    "    words, tags = [], []\n",
    "    for token in sentence:\n",
    "        words.append(token.form)\n",
    "        tags.append(token.upos)\n",
    "    train_data_proiel.append((sentence.text, {\"words\" : words, \"tags\" : tags}))\n",
    "        #forms_lemmas_dict[token.form] = [{\"l\" : token.lemma, \"p\" : token.xpos, \"s\" : \"\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Ἡροδότου Ἁλικαρνησσέος ἱστορίης ἀπόδεξις ἥδε ὡς μήτε τὰ γενόμενα ἐξ ἀνθρώπων τῷ χρόνῳ ἐξίτηλα γένηται μήτε ἔργα μεγάλα τε καὶ θωμαστά τὰ μὲν Ἕλλησι τὰ δὲ βαρβάροισι ἀποδεχθέντα ἀκλεᾶ γένηται τά τε ἄλλα καὶ δι’ ἣν αἰτίην ἐπολέμησαν ἀλλήλοισι', {'words': ['Ἡροδότου', 'Ἁλικαρνησσέος', 'ἱστορίης', 'ἀπόδεξις', 'ἥδε', 'ὡς', 'μήτε', 'τὰ', 'γενόμενα', 'ἐξ', 'ἀνθρώπων', 'τῷ', 'χρόνῳ', 'ἐξίτηλα', 'γένηται', 'μήτε', 'ἔργα', 'μεγάλα', 'τε', 'καὶ', 'θωμαστά', 'τὰ', 'μὲν', 'Ἕλλησι', 'τὰ', 'δὲ', 'βαρβάροισι', 'ἀποδεχθέντα', 'ἀκλεᾶ', 'γένηται', 'τά', 'τε', 'ἄλλα', 'καὶ', 'δι’', 'ἣν', 'αἰτίην', 'ἐπολέμησαν', 'ἀλλήλοισι'], 'tags': ['PROPN', 'NOUN', 'NOUN', 'NOUN', 'DET', 'SCONJ', 'CCONJ', 'DET', 'VERB', 'ADP', 'NOUN', 'DET', 'NOUN', 'ADJ', 'VERB', 'CCONJ', 'NOUN', 'ADJ', 'CCONJ', 'CCONJ', 'ADJ', 'PRON', 'ADV', 'NOUN', 'PRON', 'ADV', 'NOUN', 'VERB', 'ADJ', 'VERB', 'DET', 'CCONJ', 'ADJ', 'CCONJ', 'ADP', 'PRON', 'NOUN', 'VERB', 'PRON']}), ('Περσέων μέν νυν οἱ λόγιοι Φοίνικας αἰτίους φασὶ γενέσθαι τῆς διαφορῆς', {'words': ['Περσέων', 'μέν', 'νυν', 'οἱ', 'λόγιοι', 'Φοίνικας', 'αἰτίους', 'φασὶ', 'γενέσθαι', 'τῆς', 'διαφορῆς'], 'tags': ['NOUN', 'ADV', 'ADV', 'DET', 'NOUN', 'NOUN', 'ADJ', 'VERB', 'VERB', 'DET', 'NOUN']}), ('τούτους γὰρ ἀπὸ τῆς Ἐρυθρῆς καλεομένης θαλάσσης ἀπικομένους ἐπὶ τήνδε τὴν θάλασσαν καὶ οἰκήσαντας τοῦτον τὸν χῶρον τὸν καὶ νῦν οἰκέουσι αὐτίκα ναυτιλίῃσι μακρῇσι ἐπιθέσθαι ἀπαγινέοντας δὲ φορτία Αἰγύπτιά τε καὶ Ἀσσύρια τῇ τε ἄλλῃ ἐσαπικνέεσθαι καὶ δὴ καὶ ἐς Ἄργος', {'words': ['τούτους', 'γὰρ', 'ἀπὸ', 'τῆς', 'Ἐρυθρῆς', 'καλεομένης', 'θαλάσσης', 'ἀπικομένους', 'ἐπὶ', 'τήνδε', 'τὴν', 'θάλασσαν', 'καὶ', 'οἰκήσαντας', 'τοῦτον', 'τὸν', 'χῶρον', 'τὸν', 'καὶ', 'νῦν', 'οἰκέουσι', 'αὐτίκα', 'ναυτιλίῃσι', 'μακρῇσι', 'ἐπιθέσθαι', 'ἀπαγινέοντας', 'δὲ', 'φορτία', 'Αἰγύπτιά', 'τε', 'καὶ', 'Ἀσσύρια', 'τῇ', 'τε', 'ἄλλῃ', 'ἐσαπικνέεσθαι', 'καὶ', 'δὴ', 'καὶ', 'ἐς', 'Ἄργος'], 'tags': ['ADJ', 'ADV', 'ADP', 'DET', 'ADJ', 'VERB', 'NOUN', 'VERB', 'ADP', 'DET', 'DET', 'NOUN', 'CCONJ', 'VERB', 'DET', 'DET', 'NOUN', 'PRON', 'CCONJ', 'ADV', 'VERB', 'ADV', 'NOUN', 'ADJ', 'VERB', 'VERB', 'ADV', 'NOUN', 'ADJ', 'CCONJ', 'CCONJ', 'ADJ', 'DET', 'CCONJ', 'ADV', 'VERB', 'CCONJ', 'ADV', 'ADV', 'ADP', 'PROPN']})]\n"
     ]
    }
   ],
   "source": [
    "print(train_data_proiel[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data_perseus + train_data_proiel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26490"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang=\"xx\"\n",
    "nlp = spacy.blank(lang)\n",
    "tagger = nlp.create_pipe(\"tagger\")\n",
    "\n",
    "nlp.add_pipe(tagger)\n",
    "\n",
    "optimizer = nlp.begin_training()\n",
    "\n",
    "n_iter = 10\n",
    "for i in range(n_iter):\n",
    "    random.shuffle(train_data)\n",
    "    losses = {}\n",
    "        # batch up the examples using spaCy's minibatch\n",
    "    batches = minibatch(train_data, size=compounding(4.0, 32.0, 1.001))\n",
    "    for batch in batches:\n",
    "        texts, annotations = zip(*batch)\n",
    "        nlp.update(texts, annotations, sgd=optimizer, losses=losses)\n",
    "    print(\"Losses\", losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags [('ἀρχόμενος', 'VERB', 'VERB'), ('σέο', 'PRON', 'PRON'), (',', 'PUNCT', 'PUNCT'), ('Φοῖβε', 'NOUN', 'NOUN'), (',', 'PUNCT', 'PUNCT'), ('παλαιγενέων', 'ADJ', 'ADJ'), ('κλέα', 'NOUN', 'NOUN'), ('φωτῶν', 'NOUN', 'NOUN'), ('μνήσομαι', 'VERB', 'VERB'), (',', 'PUNCT', 'PUNCT'), ('οἳ', 'PRON', 'PRON'), ('Πόντοιο', 'NOUN', 'NOUN'), ('κατὰ', 'ADP', 'ADP'), ('στόμα', 'NOUN', 'NOUN'), ('καὶ', 'CCONJ', 'CCONJ'), ('διὰ', 'ADP', 'ADP'), ('πέτρας', 'NOUN', 'NOUN'), ('Κυανέας', 'NOUN', 'NOUN'), ('βασιλῆος', 'NOUN', 'NOUN'), ('ἐφημοσύνῃ', 'VERB', 'VERB'), ('Πελίαο', 'NOUN', 'NOUN'), ('χρύσειον', 'ADJ', 'ADJ'), ('μετὰ', 'ADP', 'ADP'), ('κῶας', 'NOUN', 'NOUN'), ('ἐύζυγον', 'VERB', 'VERB'), ('ἤλασαν', 'VERB', 'VERB'), ('Ἀργώ', 'ADV', 'ADV'), ('.', 'PUNCT', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "test_text = \"ἀρχόμενος σέο, Φοῖβε, παλαιγενέων κλέα φωτῶν μνήσομαι, οἳ Πόντοιο κατὰ στόμα καὶ διὰ πέτρας Κυανέας βασιλῆος ἐφημοσύνῃ Πελίαο χρύσειον μετὰ κῶας ἐύζυγον ἤλασαν Ἀργώ.\"\n",
    "doc = nlp(test_text)\n",
    "print(\"Tags\", [(t.text, t.tag_, t.pos_) for t in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags [('ἀρχόμενος', 'VERB', 'VERB'), ('σέο', 'PRON', 'PRON'), (',', 'PUNCT', 'PUNCT'), ('Φοῖβε', 'NOUN', 'NOUN'), (',', 'PUNCT', 'PUNCT'), ('παλαιγενέων', 'VERB', 'VERB'), ('κλέα', 'NOUN', 'NOUN'), ('φωτῶν', 'NOUN', 'NOUN'), ('μνήσομαι', 'VERB', 'VERB'), (',', 'PUNCT', 'PUNCT'), ('οἳ', 'PRON', 'PRON'), ('Πόντοιο', 'NOUN', 'NOUN'), ('κατὰ', 'ADP', 'ADP'), ('στόμα', 'NOUN', 'NOUN'), ('καὶ', 'CCONJ', 'CCONJ'), ('διὰ', 'ADP', 'ADP'), ('πέτρας', 'NOUN', 'NOUN'), ('Κυανέας', 'NOUN', 'NOUN'), ('βασιλῆος', 'NOUN', 'NOUN'), ('ἐφημοσύνῃ', 'ADV', 'ADV'), ('Πελίαο', 'NOUN', 'NOUN'), ('χρύσειον', 'ADJ', 'ADJ'), ('μετὰ', 'ADP', 'ADP'), ('κῶας', 'NOUN', 'NOUN'), ('ἐύζυγον', 'VERB', 'VERB'), ('ἤλασαν', 'VERB', 'VERB'), ('Ἀργώ', 'NOUN', 'NOUN'), ('.', 'PUNCT', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "test_text = \"ἀρχόμενος σέο, Φοῖβε, παλαιγενέων κλέα φωτῶν μνήσομαι, οἳ Πόντοιο κατὰ στόμα καὶ διὰ πέτρας Κυανέας βασιλῆος ἐφημοσύνῃ Πελίαο χρύσειον μετὰ κῶας ἐύζυγον ἤλασαν Ἀργώ.\"\n",
    "doc = nlp(test_text)\n",
    "print(\"Tags\", [(t.text, t.tag_, t.pos_) for t in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.to_disk(\"../data/spacy_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the model back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load it back\n",
    "nlp = spacy.load(\"../spacy_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/large_files/ag_lemma_lookup.json\"\n",
    "ag_lemma_lookup = json.load(open(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let add our table to our model\n",
    "#table = nlp.vocab.lookups.add_table(\"ag_lemma_lookup\", ag_lemma_lookup)\n",
    "table = nlp.vocab.lookups.add_table(\"lemma_exc\", ag_lemma_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.to_disk(\"../spacy_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag_lemma_lookup = nlp.vocab.lookups.get_table(\"ag_lemma_lookup\")\n",
    "ag_lemma_lookup[\"VERB\"][\"μνήσομαι\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agtenv",
   "language": "python",
   "name": "agtenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
